{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='back_to_top'></a>\n",
    "# Data Dictionary\n",
    "\n",
    "\n",
    "<br><br>\n",
    "List of Variables:<br>\n",
    "- [filename](#filename)<br>\n",
    "- [length](#length)<br>\n",
    "- [chroma stft](#chroma)<br>\n",
    "- [rms](#rms)<br>\n",
    "- [spectral_centroid](#spectral_centroid)<br>\n",
    "- [spectral_bandwidth](#spectral_bandwidth)<br>\n",
    "- [rolloff](#rolloff)<br>\n",
    "- [zero crossing rate](#zero_crossing)<br>\n",
    "- [tempo](#tempo)<br>\n",
    "- [mfcc](#mfcc)<br>\n",
    "- [label](#label)<br>\n",
    "<br>\n",
    "- [summary table of variables](#summary_table)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='filename'></a>\n",
    "<font color='blue'>**filename**</font><br><br>\n",
    "\n",
    "Name of the file / observation, following the format: genre.number.wav (eg 'blues.00000.0.wav', 'hiphop.00045.3.wav', 'rock.00016.4.wav', etc)\n",
    "\n",
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='length'></a>\n",
    "<font color='blue'>**length**</font><br><br>\n",
    "\n",
    "Length of each track observation, given in sample number. All observations are the same value of 66149 samples; at a sample rate of 22050 Hz, this amounts to approx 3 second audio samples.\n",
    "\n",
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='chroma'></a>\n",
    "<font color='blue'>**chroma_stft_mean**, **chroma_stft_var**</font><br><br>\n",
    "\n",
    "Chroma represents the tonal content of an audio signal and is closely related to the pitch class. Short time fourier transforms are used to determine the sinusoidal frequency and phase content of local sections (ie short segments) of a signal as it changes over time.<br>\n",
    "[link](https://www.researchgate.net/publication/330796993_Chroma_Feature_Extraction)<br>\n",
    "[link](https://en.wikipedia.org/wiki/Short-time_Fourier_transform#:~:text=The%20Short%2Dtime%20Fourier%20transform,as%20it%20changes%20over%20time.)\n",
    "\n",
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='rms'></a>\n",
    "<font color='blue'>**rms_mean**, **rms_var**</font><br><br>\n",
    "\n",
    "'Root mean square' is the average signal (or waveform) amplitude. Effectively, it is the average power of the signal. Root mean square is taken (as opposed to simply the arithmetic mean) in order to account for the negative sign that signals can take; signals oscillate between positive and negative.<br>\n",
    "[link](https://en.wikipedia.org/wiki/Root_mean_square)\n",
    "\n",
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='spectral_centroid'></a>\n",
    "<font color='blue'>**spectral_centroid_mean**, **spectral_centroid_var**</font><br><br>\n",
    "\n",
    "The spectral centroid is the \"centre of gravity\" of the magnitude spectrum of the STFT:\n",
    "<br><br>\n",
    "$$C_t = \\frac{\\sum_{n=1}^N M_t[n] * n}{\\sum_{n=1}^N M_t[n]}$$\n",
    "<br>\n",
    "\n",
    "where $M_t[n]$ is the magnitude of the Fourier transform at frame $t$ and frequency bin $n$. The centroid is a measure of spectral shape and higher centroid values correspond to “brighter” textures with more high frequencies.<br>[link](https://www.researchgate.net/publication/3333877_Musical_Genre_Classification_of_Audio_Signals)\n",
    "\n",
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='spectral_bandwidth'></a>\n",
    "<font color='blue'>**spectral_bandwidth_mean**, **spectral_bandwidth_var**</font><br><br>\n",
    "\n",
    "\n",
    "The spectral bandwidth describes the difference (bandwidth) between the highest and lowest frequencies (spectrum) present in the audio signal.<br> \n",
    "[link](https://www.andrew.cmu.edu/user/rk2x/telclass.dir/hw.dir/hw2s97sol.html)<br>\n",
    "[link](https://en.wikipedia.org/wiki/Spectral_width)\n",
    "\n",
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='rolloff'></a>\n",
    "<font color='blue'>**rolloff_mean**, **rolloff_var**</font><br><br>\n",
    "\n",
    "The spectral rolloff is defined as the frequency below which 85% of the magnitude distribution is concentrated. The rolloff is another measure of spectral shape.<br>[link](https://www.researchgate.net/publication/3333877_Musical_Genre_Classification_of_Audio_Signals)\n",
    "\n",
    "$$\\sum_{n=1}^{R_t} M_t [n] = 0.85 * \\sum_{n=1}^{N} M_t [n] $$\n",
    "\n",
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='zero_crossing'></a>\n",
    "<font color='blue'>**zero_crossing_rate_mean**, **zero_crossing_rate_var**</font><br><br>\n",
    "\n",
    "The zero crossing rate is the rate at which a signal changes from positive to zero to negative or from negative to zero to positive. Its value has been widely used in both speech recognition and music information retrieval, being a key feature to classify percussive sounds.<br>[link](https://en.wikipedia.org/wiki/Zero-crossing_rate)\n",
    "\n",
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='tempo'></a>\n",
    "<font color='blue'>**tempo**</font><br><br>\n",
    "\n",
    "The tempo of the track, measured in beats per minute.\n",
    "\n",
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='mfcc'></a>\n",
    "<font color='blue'>**mfcc**</font><br><br>\n",
    "\n",
    "Mel Frequency Cepstral Coefficient (MFCC) are perceptually motivated features that are also based on the STFT (short time fourier transform). After taking the log-amplitude of the magnitude spectrum, the FFT bins are grouped and smoothed according to the perceptually motivated Mel-frequency scaling. Finally, in order to decorrelate the resulting feature vectors a discrete cosine transform is performed.<br>[link](https://www.researchgate.net/publication/3333877_Musical_Genre_Classification_of_Audio_Signals)<br><br>Derivation of MFCC:<br>1. Take the Fourier transform of (a windowed excerpt of) a signal.<br>2. Map the powers of the spectrum obtained above onto the mel scale, using triangular overlapping windows.<br>3. Take the logs of the powers at each of the mel frequencies.<br>4. Take the discrete cosine transform of the list of mel log powers, as if it were a signal.<br>5. The MFCCs are the amplitudes of the resulting spectrum.<br>[link](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum)<br><br>Converting frequency scale to mel scale:$$ m = 2595 . log(1+\\frac{f}{700})$$<br>Traditionally, the first 13 coefficients are taken as they contain information about the formants. These 13 coefficients are commonly used for speech recognition.<br>Taking the first and second derivatives ($\\Delta mfcc$, and $\\Delta\\Delta mfcc$) provides further coefficients (up to 26 and 39 respectively), which assist to boost accuracy in modelling.<br><br>\n",
    "\n",
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id='label'></a>\n",
    "<font color='blue'>**label**</font><br><br>\n",
    "\n",
    "The genre of the track observation ('blues', 'hiphop', 'rock', 'classical', etc). 10 unique labels for the 10 different genres.<br> \n",
    "This is the target (dependent) variable.\n",
    "\n",
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<a id='summary_table'></a>\n",
    "\n",
    "|Variable | Description |\n",
    "| :- | :- |\n",
    "| **filename**<br><br> | Name of the file / observation, following format: genre.number.wav (eg 'blues.00000.0.wav', 'hiphop.00045.3.wav', 'rock.00016.4.wav', etc<br><br><br> |\n",
    "| **length**<br><br> | Length of each track observation, given in sample number. All observations are the same value of 66149 samples; at a sample rate of 22050 Hz, this amounts to approx 3 second audio samples.<br><br><br>|\n",
    "| **chroma_stft_mean**<br>**chroma_stft_var**<br><br> | Chroma represents the tonal content of an audio signal and is closely related to the pitch class. Short time fourier transforms are used to determine the sinusoidal frequency and phase content of local sections (ie short segments) of a signal as it changes over time.<br>[link](https://www.researchgate.net/publication/330796993_Chroma_Feature_Extraction)<br>[link](https://en.wikipedia.org/wiki/Short-time_Fourier_transform#:~:text=The%20Short%2Dtime%20Fourier%20transform,as%20it%20changes%20over%20time.)<br><br><br>|\n",
    "| **spectral_centroid_mean**<br>**spectral_centroid_var** | The spectral centroid is the \"centre of gravity\" of the magnitude spectrum of the STFT<br><br> $$C_t = \\frac{\\sum_{n=1}^N M_t[n] * n}{\\sum_{n=1}^N M_t[n]}$$<br> where $M_t[n]$ is the magnitude of the Fourier transform at frame $t$ and frequency bin $n$. The centroid is a measure of spectral shape and higher centroid values correspond to “brighter” textures with more high frequencies.<br>[link](https://www.researchgate.net/publication/3333877_Musical_Genre_Classification_of_Audio_Signals)<br><br><br> |\n",
    "| **spectral_bandwidth_mean**<br>**spectral_bandwidth_var** | The spectral bandwidth describes the difference (bandwidth) between the highest and lowest frequencies (spectrum) present in the audio signal.<br>[link](https://www.andrew.cmu.edu/user/rk2x/telclass.dir/hw.dir/hw2s97sol.html)<br>[link](https://en.wikipedia.org/wiki/Spectral_width) <br><br><br>|\n",
    "| **rolloff_mean**<br>**rolloff_var** | The spectral rolloff is defined as the frequency below which 85% of the magnitude distribution is concentrated. The rolloff is another measure of spectral shape.<br>[link](https://www.researchgate.net/publication/3333877_Musical_Genre_Classification_of_Audio_Signals)<br>$$\\sum_{n=1}^{R_t} M_t [n] = 0.85 * \\sum_{n=1}^{N} M_t [n] $$<br><br><br>|\n",
    "| **zero_crossing_rate_mean**<br>**zero_crossing_rate_var** | The zero crossing rate is the rate at which a signal changes from positive to zero to negative or from negative to zero to positive. Its value has been widely used in both speech recognition and music information retrieval, being a key feature to classify percussive sounds.<br>[link](https://en.wikipedia.org/wiki/Zero-crossing_rate) <br><br><br>|\n",
    "| **tempo**<br><br> | The tempo of the track, measured in beats per minute.<br><br><br> |\n",
    "| **mfcc**<br><br> | Mel Frequency Cepstral Coefficient (MFCC) are perceptually motivated features that are also based on the STFT (short time fourier transform). After taking the log-amplitude of the magnitude spectrum, the FFT bins are grouped and smoothed according to the perceptually motivated Mel-frequency scaling. Finally, in order to decorrelate the resulting feature vectors a discrete cosine transform is performed.<br>[link](https://www.researchgate.net/publication/3333877_Musical_Genre_Classification_of_Audio_Signals)<br><br>Derivation of MFCC:<br>1. Take the Fourier transform of (a windowed excerpt of) a signal.<br>2. Map the powers of the spectrum obtained above onto the mel scale, using triangular overlapping windows.<br>3. Take the logs of the powers at each of the mel frequencies.<br>4. Take the discrete cosine transform of the list of mel log powers, as if it were a signal.<br>5. The MFCCs are the amplitudes of the resulting spectrum.<br>[link](https://en.wikipedia.org/wiki/Mel-frequency_cepstrum)<br><br>Converting frequency scale to mel scale:$$ m = 2595 . log(1+\\frac{f}{700})$$<br>Traditionally, the first 13 coefficients are taken as they contain information about the formants. These 13 coefficients are commonly used for speech recognition.<br>Taking the first and second derivatives ($\\Delta mfcc$, and $\\Delta\\Delta mfcc$) provides further coefficients (up to 26 and 39 respectively), which assist to boost accuracy in modelling.<br><br><br> |\n",
    "| **label**<br><br> | The genre of the track observation ('blues', 'hiphop', 'rock', 'classical', etc). 10 unique labels for the 10 different genres.<br>This is the target (dependent) variable.<br><br><br> |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[(back to top)](#back_to_top)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
